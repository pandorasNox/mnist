{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'flair' from '/usr/local/lib/python3.6/dist-packages/flair/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "print(flair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(flair.__version__) #issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"The grass is green.\" - 4 Tokens\n"
     ]
    }
   ],
   "source": [
    "# The sentence objects holds a sentence that we may want to embed or tag\n",
    "from flair.data import Sentence\n",
    "\n",
    "# Make a sentence object by passing a whitespace tokenized string\n",
    "sentence = Sentence('The grass is green .')\n",
    "\n",
    "# Print the object to see what's in there\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 4 green.\n",
      "Token: 4 green.\n"
     ]
    }
   ],
   "source": [
    "# using the token id\n",
    "print(sentence.get_token(4))\n",
    "# using the index itself\n",
    "print(sentence[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 The\n",
      "Token: 2 grass\n",
      "Token: 3 is\n",
      "Token: 4 green.\n"
     ]
    }
   ],
   "source": [
    "for token in sentence:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"The grass is green .\" - 5 Tokens\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "\n",
    "# Make a sentence object by passing an untokenized string and the 'use_tokenizer' flag\n",
    "sentence = Sentence('The grass is green.', use_tokenizer=True)\n",
    "\n",
    "# Print the object to see what's in there\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Tags to Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The grass is green <color> .\n"
     ]
    }
   ],
   "source": [
    "# add a tag to a word in the sentence\n",
    "sentence[3].add_tag('ner', 'color')\n",
    "\n",
    "# print the sentence with all tags of this type\n",
    "print(sentence.to_tagged_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Labels to Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence: \"France is the current world cup winner.\" - 7 Tokens"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = Sentence('France is the current world cup winner.')\n",
    "\n",
    "# add a label to a sentence\n",
    "sentence.add_label('sports')\n",
    "\n",
    "# a sentence can also belong to multiple classes\n",
    "sentence.add_labels(['sports', 'world cup'])\n",
    "\n",
    "# you can also set the labels while initializing the sentence\n",
    "Sentence('France is the current world cup winner.', labels=['sports', 'world cup'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading CoNLL-formatted Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1196\r\n",
      "drwxr-xr-x  6 root root    192 Dec 18 19:49 .\r\n",
      "drwxr-xr-x 10 root root    320 Dec 18 19:49 ..\r\n",
      "-rw-r--r--  1 root root 137869 Dec 18 19:49 germ_eval_2018_dev_ascii.txt\r\n",
      "-rw-r--r--  1 root root 407619 Dec 18 19:49 germ_eval_2018_test_ascii.txt\r\n",
      "-rw-r--r--  1 root root 675175 Dec 18 19:49 germ_eval_2018_train_ascii.txt\r\n",
      "drwxr-xr-x  4 root root    128 Dec 18 19:48 old\r\n"
     ]
    }
   ],
   "source": [
    "!ls -al flair_tut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flair_tut/germ_eval_2018_dev_ascii.txt', 'flair_tut/germ_eval_2018_train_ascii.txt', 'flair_tut/germ_eval_2018_test_ascii.txt']\n"
     ]
    }
   ],
   "source": [
    "from flair.data_fetcher import NLPTaskDataFetcher\n",
    "import glob\n",
    "\n",
    "# use your own data path\n",
    "#data_folder = 'flair_tut/germ_eval_2018_dev.txt'\n",
    "data_file = glob.glob('flair_tut/*.txt')\n",
    "\n",
    "print(data_file)\n",
    "\n",
    "# get training, test and dev data\n",
    "sentences = NLPTaskDataFetcher.read_text_classification_file(data_file[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
