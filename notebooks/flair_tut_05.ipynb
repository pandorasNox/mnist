{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'flair' from '/usr/local/lib/python3.6/dist-packages/flair/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "print(flair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"The grass is green .\" - 5 Tokens\n"
     ]
    }
   ],
   "source": [
    "# The sentence objects holds a sentence that we may want to embed or tag\n",
    "from flair.data import Sentence\n",
    "\n",
    "# Make a sentence object by passing a whitespace tokenized string\n",
    "sentence = Sentence('The grass is green .')\n",
    "\n",
    "# Print the object to see what's in there\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1196\r\n",
      "drwxr-xr-x  6 root root    192 Dec 18 19:49 .\r\n",
      "drwxr-xr-x 11 root root    352 Dec 18 19:59 ..\r\n",
      "-rw-r--r--  1 root root 137869 Dec 18 19:49 germ_eval_2018_dev_ascii.txt\r\n",
      "-rw-r--r--  1 root root 407619 Dec 18 19:49 germ_eval_2018_test_ascii.txt\r\n",
      "-rw-r--r--  1 root root 675175 Dec 18 19:49 germ_eval_2018_train_ascii.txt\r\n",
      "drwxr-xr-x  4 root root    128 Dec 18 19:48 old\r\n"
     ]
    }
   ],
   "source": [
    "!ls -al flair_tut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flair_tut/germ_eval_2018_dev_ascii.txt', 'flair_tut/germ_eval_2018_train_ascii.txt', 'flair_tut/germ_eval_2018_test_ascii.txt']\n",
      "3532\n"
     ]
    }
   ],
   "source": [
    "from flair.data_fetcher import NLPTaskDataFetcher\n",
    "import glob\n",
    "\n",
    "# use your own data path\n",
    "data_files = glob.glob('flair_tut/*.txt')\n",
    "\n",
    "#data_folder = './flair_tut'\n",
    "#sentences: List[Sentence] = NLPTaskDataFetcher.read_text_classification_file(data_folder)\n",
    "\n",
    "\n",
    "print(data_files)\n",
    "#for file_path in data_files:\n",
    "#    print(file_path)\n",
    "\n",
    "# get training, test and dev data\n",
    "dev_sentences = NLPTaskDataFetcher.read_text_classification_file('flair_tut/germ_eval_2018_dev_ascii.txt')\n",
    "train_sentences = NLPTaskDataFetcher.read_text_classification_file('flair_tut/germ_eval_2018_train_ascii.txt')\n",
    "test_sentences = NLPTaskDataFetcher.read_text_classification_file('flair_tut/germ_eval_2018_test_ascii.txt')\n",
    "\n",
    "print(len(test_sentences))\n",
    "\n",
    "\n",
    "#for sentence in sentences:\n",
    "#    print(len(sentence))\n",
    "\n",
    "#for sen in sentences\n",
    "#for line in f:\n",
    "#    words = line.split()\n",
    "\n",
    "#corpus = TaggedCorpus(sent_train, sen_test, sent_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import TaggedCorpus\n",
    "\n",
    "# 1. get the corpus\n",
    "corpus = TaggedCorpus(train_sentences, test_sentences, dev_sentences)\n",
    "\n",
    "from flair.data import TaggedCorpus\n",
    "from flair.data_fetcher import NLPTaskDataFetcher, NLPTask\n",
    "from flair.embeddings import WordEmbeddings, CharLMEmbeddings, DocumentLSTMEmbeddings\n",
    "from flair.models.text_classification_model import TextClassifier\n",
    "from flair.trainers.text_classification_trainer import TextClassifierTrainer\n",
    "\n",
    "# 2. create the label dictionary\n",
    "label_dict = corpus.make_label_dictionary()\n",
    "\n",
    "# 3. make a list of word embeddings\n",
    "word_embeddings = [WordEmbeddings('de')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. init document embedding by passing list of word embeddings\n",
    "document_embeddings: DocumentLSTMEmbeddings = DocumentLSTMEmbeddings(word_embeddings,\n",
    "                                                                     hidden_states=512,\n",
    "                                                                     reproject_words=True,\n",
    "                                                                     reproject_words_dimension=256,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. create the text classifier\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict, multi_label=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. initialize the text classifier trainer\n",
    "trainer = TextClassifierTrainer(classifier, corpus, label_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-18 20:21:39,147 ----------------------------------------------------------------------------------------------------\n",
      "2018-12-18 20:21:40,235 epoch 1 - iter 0/157 - loss 0.02186223\n",
      "2018-12-18 20:21:45,206 epoch 1 - iter 15/157 - loss 0.02008372\n",
      "2018-12-18 20:21:49,855 epoch 1 - iter 30/157 - loss 0.02001520\n",
      "2018-12-18 20:21:54,654 epoch 1 - iter 45/157 - loss 0.02004068\n",
      "2018-12-18 20:21:59,254 epoch 1 - iter 60/157 - loss 0.02020064\n",
      "2018-12-18 20:22:04,095 epoch 1 - iter 75/157 - loss 0.02011204\n",
      "2018-12-18 20:22:08,561 epoch 1 - iter 90/157 - loss 0.02009813\n",
      "2018-12-18 20:22:13,576 epoch 1 - iter 105/157 - loss 0.02003611\n",
      "2018-12-18 20:22:18,196 epoch 1 - iter 120/157 - loss 0.01994515\n",
      "2018-12-18 20:22:22,765 epoch 1 - iter 135/157 - loss 0.01999470\n",
      "2018-12-18 20:22:27,057 epoch 1 - iter 150/157 - loss 0.02001688\n",
      "2018-12-18 20:22:28,995 ----------------------------------------------------------------------------------------------------\n",
      "2018-12-18 20:22:28,995 EPOCH 1: lr 0.1000 - bad epochs 0\n",
      "2018-12-18 20:22:42,523 TRAIN: loss 0.01981089 - f-score 0.6630 - acc 0.6630\n",
      "2018-12-18 20:22:52,348 DEV  : loss 0.01994755 - f-score 0.6597 - acc 0.6597\n"
     ]
    }
   ],
   "source": [
    "# 7. start the trainig\n",
    "trainer.train('resources/ag_news/results',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              anneal_factor=0.5,\n",
    "              patience=1,\n",
    "              max_epochs=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. plot training curves (optional)\n",
    "from flair.visual.training_curves import Plotter\n",
    "plotter = Plotter()\n",
    "plotter.plot_training_curves('resources/ag_news/results/loss.tsv')\n",
    "plotter.plot_weights('resources/ag_news/results/weights.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo\n"
     ]
    }
   ],
   "source": [
    "print('foo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "res_sentences = model.predict(Sentence('France is the current world cup winner.'))\n",
    "for res_sentence in res_sentences:\n",
    "    print(res_sentence.labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
